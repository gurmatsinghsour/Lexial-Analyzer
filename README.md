# Lexical Analyzer
The Lexical Analyzer is a software tool that takes a source code file and breaks it down into a sequence of tokens or lexemes. 
These tokens are then used by the compiler or interpreter to analyze and execute the code. The Lexical Analyzer is an essential component of the compiler and interpreter
design process, as it provides the first step in transforming human-readable code into machine-executable code.

This project is an implementation of a simple lexical analyzer using Python. The program takes a source code file as input and generates a list of tokens and their corresponding lexemes. The program can recognize several types of tokens, including keywords, identifiers, operators, and literals.

# Usage

To use the Lexical Analyzer, follow these steps:
1. Clone the repository onto your local machine.
2. Open a terminal window and navigate to the directory containing the lexical_analyzer.py file.
3. Run the program by typing python lexical_analyzer.py <input_file> in the terminal, where <input_file> is the path to the source code file you wish to analyze.
4. The program will generate a list of tokens and their corresponding lexemes and display them in the terminal.

# Limitations

This implementation of the Lexical Analyzer is designed to handle simple source code files and may not work correctly with more complex code. Additionally, the program does not perform any error checking or handling and may generate incorrect output if the input file contains syntax errors or other issues.
